# CPU

## 第六章 机制：受限直接执行

### 虚拟化CPU以实现共享物理CPU

#### 问题一：性能，如何在不增加开销的情况下实现虚拟化

#### 问题二：控制权，如何有效的运行进程，同时保留对CPU的控制权

### 受限直接执行（LDE）limited direct execution

#### 问题一：受限制的操作

例如发出I/O请求或获得更多系统资源

解决：通过陷阱（trap）指令进入内核模式，完成受限操作后再调用从陷阱返回指令（return-from-trap）返回用户模式。

x86执行陷阱时，处理器将程序计数器、标志和其他一些寄存器推送到每个进程的内核栈（kernel stack）上。从返回陷阱将从栈弹出这些值，并恢复执行用户模式程序。

内核在启动时设置陷阱表（trap table）来实现。

LDE协议有两个阶段。第一个阶段（在系统引导时），内核初始化陷阱表。第二个阶段（运行进程时），在使用陷阱返回指令，开始执行进程之前，内核设置一些内容（例如，在进程列表中分配一个节点，分配内存）。然后CPU切换到用户模式并开始执行该进程。当进程希望发出系统调用时，会重新切换为内核模式，然后再通过返回陷阱指令返回，该进程继续执行，并从main()返回。OS清理干净，任务结束。

#### 问题二：在进程之间切换

关键：如何重获CPU的控制权

1.等待系统调用（可能进入无限循环）

2.操作系统进行控制（使用硬件提供的时钟中断功能）

时钟中断时，硬件要为正在运行的程序保存足够的状态。

##### 保存和恢复上下文：

存在两种寄存器保存/恢复。

第一种是发生时钟中断时，运行进程的用户寄存器由硬件隐式保存，使用该进程的**内核栈**。

第二种是操作系统决定从A切换到B，此时内核寄存器被软件（OS）明确的保存，但存储在该进程的**进程结构**的内存中。

总过程：进程A正在运行，然后被中断时钟中断。硬件保存它的寄存器（在内核栈中），并进入内核。操作系统决定切换到进程B。此时调用switch()例程，该例程仔细保存当前寄存器的值（保存到A的进程结构），恢复寄存器进程B（从进程结构B中），然后切换上下文，即通过改变栈指针来是使用B的内核栈。最后操作系统从陷阱返回，恢复B的寄存器，并运行它。

## 第七章 进程调度：介绍

周转时间：任务完成时间减去任务到达系统的时间

响应时间：任务到达系统首次运行的时间

### 先进先出（FIFO，First In First Out）

### 最短任务优先（SJF，Shortest Job First）

假设所有任务同时到大，SJF是最优的调度算法。但若是一个长任务先到达，周转时间将变长。

### 最短完成时间优先（STCF，Shortest Time-to-Completion First）

向SJF添加抢占，每当新工作进入系统时，它就会确定剩余工作和新工作谁的剩余时间更少，然后调度该工作。

假设工作可以随时到达，则STCF是最优的

### 轮转（RR，Round-Robin）

在一个时间片内运行一个工作，然后切换到任务队列的下一个工作。

响应时间大大减少。

时间片的长度必须是时钟中断周期的倍数。需要权衡时间片的长度，以便摊销上下文切换的成本。

上下文切换的成本不仅仅包括，来自保存和恢复少量寄存器的操作系统操作，还在CPU高速缓存、TLB、分支预测器和其他片上硬件中建立了大量的状态，切换到另一个工作将会导致此状态刷新。

任何公平的策略，即在小规模的时间内将CPU均匀分配到活动进程之间，在周转时间这类指标上表现不佳。

**第一种：SJF、STCF优化周转时间，但对响应时间不利。**

**第二种：RR优化响应时间，但对周转时间不利。**

考虑到IO操作，应该实现重叠（即在一个进程在阻塞等待IO操作时，CPU调度到另一个进程以节约CPU资源）。

### **如何知道每个工作的长度？**

## 第八章 调度：多级反馈队列

### 多级反馈队列（MLFQ，Multi-level Feedback Queue）

解决了两方面问题：1、优化周转时间。2、降低响应时间。

基本规则：MLFQ中存在许多独立的队列，每个队列有不同的优先级，任何时刻，一个工作只能存在于一个队列中。MLFQ总是执行执行较高的优先级的工作。在一个队列中，采用轮转调度。

#### 规则一

如果A的优先级>B的优先级，运行A（不运行B）。

#### 规则二

如果A的优先级=B的优先级，轮转运行A和B。

#### 规则三

工作进入系统时，放在最高优先级（最上层队列）。

#### 规则四

一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次CPU），就降低其优先级（移入低一级队列）。

#### 规则五

经过一段时间S，就将系统中所有工作重新加入最高优先级队列。

#### 特点

不需要预先知道任务的运行时间，而是观察任务的运行来给出对应的优先级。对于短时间的交互型工作，获得类似SJF/STCF的很好的全局性能，同时对于长时间运行的CPU密集型负载也可以公平地，不断地稳步向前。

## 第九章 调度：比例份额

### 基本概念：彩票（ticket）数代表份额

### 彩票机制

1、用户内部用自己货币，再根据货币给各个任务分发彩票

2、彩票转让，常见于客户端/服务端交互，客户端转让彩票给服务端，服务端执行结束后会将这部分彩票归还给客户端

3、彩票通胀：一个进程可以临时提升或降低自己拥有的彩票数量，可用于进程之间相互信任的环境

### 实现

使用列表来记录系统中所用进程，以及彩票的总数。

假设有A、B、C三个进程，每个进程有一定数量彩票。

做出调度决策前，从彩票总数400中选择一个随机数，假设为300，然后遍历链表，用一个计数器找到中奖者。代码从前向后遍历链表，将每张票的值加到`counter`上，直到值超过`winnner`。

为使过程更有效率，建议将列表项按照彩票数递减排序，能保证使用最小的迭代次数找到节点。

![image-20220726203459202](C:\Users\98449\AppData\Roaming\Typora\typora-user-images\image-20220726203459202.png)

```c
// counter: used to track if we’ve found the winner yet
int counter = 0;
// winner: use some call to a random number generator to
// get a value, between 0 and the total # of tickets
int winner = getrandom(0, totaltickets);
// current: use this to walk through the list of jobs
node_t *current = head;
while (current) {
  counter = counter + current->tickets;
  if (counter > winner)
    13 break; // found the winner
  current = current->next;
}
// ’current’ is the winner: schedule it...
```

### 公平性

当工作执行很短时，平均不公平度差，只有当工作执行非常多的时间片时，彩票调度才能得到期望的结果。

### 如何分配彩票？（没有最佳答案）

### 随机性优化

在工作运行时间很短时，不能产生正确的比例。

Waldspurger提出步长调度。

##### 步长调度

系统中每个工作都有自己的步长，这个值与票数值成反比。在上面的例子中，A、B、C这3个工作的票数分别是100、50和250，我们通过一个大数分别除以他们的票数来获得每个进程的步长。比如用10000除以这些票数值，得到3个进程的步长分别为100、200和40。我们称这个值为每个进程的步长（stride）。每次进程运行后，我们会让它的计数器（称为行程(pass)）来增加它的步长，记录它的总体进展。

基本思路：当需要进行调度时，选择拥有最小行程值的进程，并且在运行之后，将该进程的行程值加一个步长。

Waldspurger给出的伪代码

```c
current = remove_min(queue); // pick client with minimum pass
schedule(current); // use resource for quantum
current->pass += current->stride; // compute next pass using stride
insert(queue, current); // put back into the queue
```

在我们的例子中，3 个进程（A、B、C）的步长值分别为100、200 和40，初始行程值都为0。因此，最初，所有进程都可能被选择执行。假设选择A（任意的，所有具有同样低的行程值的进程，都可能被选中）。A 执行一个时间片后，更新它的行程值为100。然后运行B，并更新其行程值为200。最后执行C，C 的行程值变为40。这时，算法选择最小的行程值，是C，执行并增加为80（C 的步长是40）。然后C 再次运行（依然行程值最小），行程值增加到120。现在运行A，更新它的行程值为200（现在与B 相同）。然后C 再次连续运行两次，行程值也变为200。此时，所有行程值再次相等，这个过程会无限地重复下去。

![image-20220726212456093](C:\Users\98449\AppData\Roaming\Typora\typora-user-images\image-20220726212456093.png)

#### 优点

实现精确控制

#### 缺点

需要设置一个全局状态，而彩票调度不需要。假如一个新的进
程在上面的步长调度执行过程中加入系统，应该怎么设置它的行程值呢？设置成0 吗？这样的话，它就独占CPU 了。

此彩票调度算法能够更合理地处理新加入的进程。

# 内存

## 内存交换

当访问超出物理内存大小时，需要在页表结构添加额外信息，比如增加一个存在位（present bit，或者其他类似机制），告诉我们页是否在内存中，如果不存在，则操作系统页错误处理程序会运行以处理页错误，从而将需要的页从硬盘读取到内存，可能还要先换出内存中的一些页，为即将换入的页腾出空间。

### 交换空间

在硬盘中开辟一部分用于物理页的移入与移出，这样的空间称为交换空间（如Linux的swap分区，Windows的虚拟内存）。

### 存在位

存在位设置为1，表示该页存在于物理内存中，设置为0，表示该页在磁盘中。

### 页错误

访问不在物理内存中的页，这种行为被称为页错误（page fault）。

在页错误时，操作系统被唤起处理页错误，一段称为“页错误处理程序”（page-fault handler）的代码会执行。

PS：之所以称为错误是因为，当发生这种情况时，硬件将控制权交回给操作系统，硬件能做的就是触发异常，这与进程执行非法操作处理流程一样，所以称为错误。

#### 为什么硬件不能处理页错误

1、页错误导致的硬盘操作很慢，即使操作系统需要很长时间来处理故障，执行大量指令，但相比于硬盘操作，这些额外开销很小。

2、如果要处理这些故障的话，硬盘必须了解交换空间，如何向硬盘发起I/O操作，等等。由于性能和简单的原因，所以不进行处理。

#### TLB未命中

```c
1 VPN = (VirtualAddress & VPN_MASK) >> SHIFT
2 (Success, TlbEntry) = TLB_Lookup(VPN)
3 if (Success == True) // TLB Hit
4 if (CanAccess(TlbEntry.ProtectBits) == True)
5 Offset = VirtualAddress & OFFSET_MASK
6 PhysAddr = (TlbEntry.PFN << SHIFT) | Offset
7 Register = AccessMemory(PhysAddr)
8 else
9 RaiseException(PROTECTION_FAULT)
10 else // TLB Miss
11 PTEAddr = PTBR + (VPN * sizeof(PTE))
12 PTE = AccessMemory(PTEAddr)
13 if (PTE.Valid == False)
14 RaiseException(SEGMENTATION_FAULT)
15 else
16 if (CanAccess(PTE.ProtectBits) == False)
17 RaiseException(PROTECTION_FAULT)
18 else if (PTE.Present == True)
19 // assuming hardware-managed TLB
20 TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits)
21 RetryInstruction()
22 else if (PTE.Present == False)
23 RaiseException(PAGE_FAULT)
```

有3种重要情景。  
1、该页存在且有效（第18-21行），在这种情况下，TLB未命中处理程序可以简单的冲PTE中获取PFN，然后重试指令（这次TLB会命中）  
2、该页不在内存中，运行页错误处理程序（第22-23行）  
3、访问无效页，操作系统陷阱处理程序运行，可能会杀死非法进程（第13-14行）

### 高低水位线

大多数操作系统会设置高水位线（High Watermark），低水位线（Low Watermark），当操作系统发现少于LW个页可用时，后台分则释放内存的线程会开始运行，知道有HW个可用的物理页。这个后台线程称为交换守护进程或页守护进程，完成任务后进入休眠状态。

## 内存替换策略

### 最优替换策略(optimal)

替换内存中在最远将来才会被访问到的页，但是实现不了。  

### 缓存未命中的类型

#### 强制性未命中(compulsory miss)

又称为冷启动未命中，因为缓存一开始是空的，这是对项目的第一次引用。

#### 容量未命中(capacity miss)

缓存的空间不足而不得不踢出一个项目以将新项目引入缓存。

#### 冲突未命中(conflict miss)

这种未命中出现在硬件中，因为硬件缓存中对项的放置位置有限制，这是由于所谓的集合关联性。它不会出现在操作系统页面缓存中，因为这样的缓存总是完全关联的，即对页面放置的内存位置没有限制。

冲突未命中（conflict miss) 和缓存的实现方式有关。大多数缓存，尤其是硬件缓存，由于它们需要设计的较为简单，因此限制了**块**可以被放置的位置。例如 block i 只能放在 block (**i mod cache size**) 的地方，以上图为例，缓存的大小为4，如果要取 block 8的数据，则只能放在缓存的第0块，同样，block 9 放在缓存的 block  1处。因此，如果要取的块为 block 0， block 4，block 8，那么计算出来都应该放在缓存 block 0的位置，因此放  block 4时，会覆盖原来 block 0的数据，加入需要循环的访问 block 0，block 8，block 0，block  8，这样就会一直不能命中，即使缓存有多余的空间，但位置的限制导致一直覆盖缓存上 block 0 的数据，造成**冲突未命中**。![image-20220830195516083](E:\笔记\操作系统导论.assets\image-20220830195516083.png)

### FIFO 先入先出

### 随机策略

### LRU 最近最少使用

基于局部性原则（时间，空间局部性）  
在大多数情况下，这种策略效果不错

### 各个策略特点

1、当工作负载不存在局部性时，使用的策略区别不大。 ![image-20220830203301410](E:\笔记\操作系统导论.assets\image-20220830203301410.png)
2、80-20负载场景（80%的引用是访问20%的热门页，20%的引用时剩余80%的冷门页），尽管随机和FIFO都很好的运行，但LRU更好 ![image-20220830203211186](E:\笔记\操作系统导论.assets\image-20220830203211186.png) 
3、循环顺序负载，依次引用50个页，从0开始，然后是1，...，49，然后循环  
在许多应用程序（如数据库)中非常常见，LRU和FIFO最差。这些算法在循环顺序的工作负载下，踢出较久的页。即使缓存的大小是49页，50个页面的循环连续负载也会导致0%的命中率。随机策略效果明显更好。  
![image-20220830203233492](E:\笔记\操作系统导论.assets\image-20220830203233492.png)

### LRU如何实现

有一种方法，在页表中保存时间字段，但是不可行，这样的话每次踢出页都要遍历页表。

### 近似LRU

硬件添加一个使用位（use bit，有事称为引用位 reference bit），每当页被引用时，硬件将使用位 置于1，但是硬件不会清除使用位（由操作系统负责） 

Corbato时钟算法：时钟指针开始时指向某个特定的页，当要进行页替换时，操作系统检查当前指向的页P的使用位是1还是0，如果是1，则将使用位置于0，时钟指针递增到下一页（P+1），直到找到一个使用位为0的页。最坏的情况是遍历一次页表，具有不重复扫描内存来寻找未使用页的特点

下图真是时钟算法的一个变种行为：在需要进行页替换时随机扫描各页，如果遇到一个页的引用位为1，就将该位设置为0，直到找到一个使用位为0的页，将这个页替换。  
![image-20220830203539166](E:\笔记\操作系统导论.assets\image-20220830203539166.png)

### 脏页

如果页已被修改并因此变脏，则踢出它必须把它写入磁盘，代价很昂贵。如果它没被修改，踢出就没成本，物理帧可以简单地重用于其他目的而无须额外的I/O，因此，一些虚拟机系统更倾向与踢出干净页。

为了支持这种行为，硬件应该包括一个修改位（modified bit，又名脏位，dirty bit），每次写入页时都会设置此位。例如时钟算法可以改动，以扫描即未使用又干净的页先踢出。

### 其他虚拟内存策略介绍

#### 预取（prefetching）

操作系统预测一个页面即将被使用，从而提前载入，这种行为称为预取，例如代码页P被载入内存，那么代码页P+1也很有可能被载入

#### 聚集写入、分组写入（clustering,grouping）

许多系统会在内存中收集一些待完成写入，并以一种更高效的写入方式将它们写入磁盘，这种行为称为聚集写入，或者就是分组写入

### 抖动

正在运行的进程内存需求超过了可用物理内存，在这种情况下，系统将不断地进行换页，这种行为称之为抖动（thrashing）

#### 解决方法一：准入控制

系统不运行部分进程，希望减少进程的工作集能放入内存

#### 解决方法二：杀死进程

### 扩展：ARC算法，类似LRU，但避免LRU的最坏情况行为

## VAX/VMS虚拟内存系统

### 内核映射

![image-20220831224607905](E:\笔记\操作系统导论.assets\image-20220831224607905.png)

在上下文切换时，操作系统改变P0和P1寄存器以指向即将运行的进程的适当页表，但是不改变**S基址和界限寄存器**，以此达到将“相同的”内核结构映射到每个用户的地址空间  
如果内核完全位于物理内存中，那么将页表的交换页切换到磁盘是非常困难的。如果内核被赋予了自己的地址空间，那么在用户程序和内核之间移动数据将变的复杂，通过这种构造（**现在广泛使用**）内核几乎就像应用程序库一样。

### 页替换

没有使用引用位，使用分段FIFO的策略

#### 分段FIFO

每个进程都有一个可以保存在内存中的最大页数，称为驻留页大小（Resident Set Size,RSS）。每个页都保存在FIFO列表中，当一个进程超过RSS时，先入的页被驱逐，**不需要任何硬件支持**

##### 二次机会列表（second-chance-list）

纯粹的FIFO不是很好，为了提升FIFO的性能，引入两个二次机会列表（second-chance-list）,页在从内存中被踢出之前被放在其中，具体来说是全局的干净页空闲列表和脏页列表。当进程P超过其RSS时，将从其每个进程的FIFO中移除一个页。如果页是干净的，则将其放在干净页列表的末尾。如果页是脏的，则将其放在脏页列表的末尾。  
如果另一个进程Q需要一个空闲页，它会从全局干净列表中取出第一个空闲页。但是如果原来的进程P在回收之前在该页上出现页错误，则P会从空闲（或脏）列表中回收，从而避免昂贵的磁盘访问。这些全局二次机会列表越大，分段的FIFO算法就越接近LRU。

### 页聚集

对页分组，执行更少和更大的写入，从而提高性能。（因为磁盘在大型传输中效果更好，较减少了寻道时间）

### 按需置零（demand zeroing）

常规做法：  
地址空间添加一个页的例子：在一个初级实现中，操作系统响应一个请求，在物理内存中找到页，将页添加到堆中，并将之置零，然后将其映射到地址空间中（设置页表以根据需要引用该物理页）。在页没有被进程使用时，代价很昂贵。

按需置零：  
当页添加到地址空间时，操作系统的工作很少。它会在页表中放入一个标记 页不可访问的 条目。如果进程读取或写入页，则向操作系统发送**陷阱**。在处理页时，操作系统注意到（通常通过页表项中“保留的操作系统字段”部分标记的一些位），这是一个按需置零页。之后，操作系统再完成寻找物理页的必要操作，将它置零，并映射到进程的地址空间。

好处：在进程不访问此页的时候，这些操作就可以避免。属于惰性操作。

### 写入时复制（copy-on-write）

如果操作系统需要将一个页面从一个地址空间复制到另一个地址空间，不是实际复制它，而是将其映射到目标地址空间，并在两个地址空间中将其标记为已读。如果两个地址空间都只读取页面，则不会采取进一步操作，实现了快速复制而不实际移动任何数据。

但是，如果其中一个地址空间确实尝试写入页面，就会陷入操作系统。操作系统会注意到该页面是一个COW页面，因此惰性地分配一个新页，填充数据，并将这个新页映射到错误处理的地址空间，然后继续。

#### fork()和exec()和COW

fork()会创建调用者地址空间的精确副本，对于大的地址空间，这样的复制过程很慢，并且是数据密集的。通常，大部分的地址空间会被随后的exec()调用立即覆盖，它用即将执行的程序覆盖进程的地址空间。  
通过使用写时复制的fork()，避免了大量不必要的复制。（一开始调用fork()的时候，只是快速复制，只有在写入的时候，才真正的创建新页写入）

# 并发

## 线程与进程

每个线程类似于独立的进程，只有一点区别，**它们共享地址空间**，从而能够访问相同的数据

线程之间的上下文切换类似于进程间的上下文切换，对于进程，我们将状态保存到进程控制块（Process Control Block，PCB）。对于线程，保存到线程控制块（Thread Control Block，TCB）。  
线程与进程的上下文切换有一点主要区别，地址空间保持不变（即不需要切换当前使用的页表）

另一个主要区别在于栈。![image-20220901201342881](E:\笔记\操作系统导论.assets\image-20220901201342881.png)   


左图为传统进程地址空间模型（单线程进程），只有一个栈，通常位于地址空间的底部  
右图为多线程的进程地址空间模型，**每个线程都有一个栈**，右图中，可以看到两个栈跨越了进程的地址空间。  
所有位于栈上的变量、参数、返回值和其他放在栈上的东西，将被放置在有时称为线程本地（thread-local）存储的地方，即相关线程的栈。

运行时，每个线程都有自己的专用寄存器

### 关键并发术语

#### 临界区

临界区（critical section）是访问共享资源的一段代码，资源通常是一个变量或数据结构

#### 竞态条件

竞态条件（race condition）出现在多个执行线程大致同时进入临界区时，它们都试图更新共享的数据结构，导致了非期望的结果

#### 不确定性

不确定性（indeterminate）程序由一个或多个竞态条件组成，程序的输出因运行而异，具体取于哪些线程在何时运行，这导致结果是不确定的（deterministic）

#### 互斥执行

为了避免这些问题，线程应该使用某种互斥（mutual exclusion）原语，这样可以保证只有一个线程进入临界区，从而避免出现竞态，并产生确定的程序输出。

#### 原语

原语是指由若干条机器指令构成的，并用以完成特定功能的一段程序。这段程序在执行期间是不可分割的。其主要特点是不可分割性。

## 锁

### 评价锁

#### 互斥

锁是否有效？

#### 公平性

当锁可用时，是否每一个竞争线程有公平的机会抢到锁？是否有竞争锁的线程会饿死？

#### 性能

没有竞争时，只有一个线程抢锁，释放锁的开支如何？一个CPU上多个线程竞争，性能如何？多个CPU，多个线程竞争时的性能？

### 控制中断

临界区关闭中断  
优点：简单  
缺点：这种方法允许所有调用线程执行特权操作（打开关闭中断），恶意程序可能独占CPU，只能重启系统  
		   不支持多处理器，当位于不同CPU的线程试图进入临界区时，关闭中断没有作用  
		   效率低

### 自旋

### 测试并设置指令（test-and-set-instruction）

```c
int
TestAndSet (int *old_ptr, int new)
{
  int old = *old_ptr; // fetch old value at old_ptr
  *old_ptr = new;     // store ’new’ into old_ptr
  return old;         // return the old value
}

typedef struct lock_t
{
  int flag;
} lock_t;

void
init (lock_t *lock)
{
  lock->flag = 0;
}

void
lock (lock_t *lock)
{
  while (TestAndSet (&lock->flag, 1) == 1)
    ;
}

void
unlock (lock_t *lock)
{
  lock->flag = 0;
}
```

返回old_ptr的旧值，并赋予其新值

### 比较并交换（compare-and-swap）CAS

```c
int
CompareAndSwap (int *ptr, int expected, int new)
{
  int actual = *ptr;
  if (actual == expected)
    *ptr = new;
  return actual;
}
```

比较指针的值与目标值是否相同，相同则将指针的值修改为新值

### 链接的加载（load-linked）和条件式存储（store-conditional）

链接的加载指令和典型加载指令类似，都是从内存中取出值存入一个寄存器。  
关键区别在于条件式存储指令：只有上一次加载的地址在期间没有更新时，才会成功

```c
int
LoadLinked (int *ptr)
{
  return *ptr;
}

int
StoreConditional (int *ptr, int value)
{
  if (1) // loadlinked地址的值没有发生更改
    {
      *ptr = value;
      return 1;
    }
  else
    {
      return 0;
    }
}
```

```c
void
lock (lock_t *lock)
{
  while (1)
    {
      while (LoadLinked (&lock->flag) == 1)
        ;
      if (StoreConditional (&lock->flag, 1) == 1)
        {
          return;
        }
    }
}

void
unlock (lock_t *lock)
{
  lock->flag = 0;
}
```



### 获取并增加（fetch-and-add）

能原子地返回特定地址的旧值，并且让该值自增一

```c
int
FetchAndAdd (int *ptr)
{
  int old = *ptr;
  *ptr = old + 1;
  return old;
}
```

```c
typedef struct __lock_t
{
  int ticket;
  int turn;
} lock_t;

void
lock_init (lock_t *lock)
{
  lock->ticket = 0;
  lock->turn = 0;
}

void
lock (lock_t *lock)
{
  int myturn = FetchAndAdd (&lock->ticket);
  while (lock->turn != myturn)
    ; // spin
}

void
unlock (lock_t *lock)
{
  lock->turn = lock->turn + 1;

```

本方法能保证所有线程都能抢到锁。只要一个线程获得了ticket值，它最终会被调度

### 休眠代替自旋 ：使用队列

### 两阶段锁

两阶段锁的第一阶段会先自旋一段时间，希望它可以获取锁。但是如果第一阶段没有获取锁，第二阶段调用者会睡眠，直到锁可用

### 懒惰计数器

懒惰计数器通过多个局部计数器和一个全局计数器来实现一个逻辑计数器，其中每个CPU核心有一个局部计数器。每个CPU都有自己的局部计数器，不同CPU上的线程不会竞争

局部值定期转移给全局计数器（让全局计数器加上局部计数器的值）

这种局部转全局的频度，取决于一个阈值，这里称为S（表示sloppiness）  
S越小，懒惰计数器则越趋近于非扩展的计数器。S越大，扩展性越强，但是全局计数器与实际计数器的偏差越大。  
如果S大，性能很好，但是全局计数器会有延时。

## 条件变量

线程使用条件变量(condition variable) 来等待一个条件变成真.

条件变量是一个显示队列,当条件不满足时,线程可以把自己加入队列,等待该条件.另外的线程,改变了状态后,就可以唤醒一个或者多个等待线程(通过在该条件上发信号),让它们继续执行.

以下为代码样例:

```c
pthread_cond_wait (pthread_cond_t *c, pthread_mutex_t *m);
pthread_cond_signal (pthread_cond_t *c);

int done = 0;
pthread_cond_t c = PTHREAD_COND_INITIALIZER;
pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;

void
thr_exit ()
{
  pthread_mutex_lock (&m);
  done = 1;
  pthread_cond_signal (&c);
  pthread_mutex_lock (&m);
}

void *
child (void *arg)
{
  printf ("child\n");
  thr_exit ();
  return NULL;
}

void
thr_join ()
{
  pthread_mutex_lock (&m);
  while (done == 0)
    {
      pthread_cond_wait (&c, &m);
    }
  pthread_mutex_unlock (&m);
}

int
main (int argc, char *argv[])
{
  printf ("parent:begin\n");
  pthread_t p;
  pthread_create (&p, NULL, child, NULL);

  thr_join ();
  printf ("parent:end\n");
  return 0;
}
```

wait()参数中都有一个互斥量,它假定在wait()调用的时候,这个互斥量是已上锁状态.wait()的职责是释放锁,并让调用线程休眠(原子地)

**调用signal和wait时要持有锁!**

#### 细节

1. 调用pthread_cond_wait前要先对互斥量mutex上锁,才能将&mutex传入pthread_cond_wait函数中 
2. 在pthread_cond_wait 函数内部,会先对mutex解锁
3. 在等待地条件到来后,pthread_cond_wait 函数在返回前会对mutex加锁

#### 解释

1. 传入后解锁是为了条件能够改变,  
   传入后的解锁,是因为调用 pthread_cond_signal 的那部分，需要先加锁更改条件后才调用pthread_cond_signal。（更改条件与等待条件满足，都是针对条件这一个资源的竞争，所以调用 pthread_cond_wait 和调用 pthread_cond_signal 的两个线程需要同一把锁  
   如果 pthread_cond_wait 内不对 mutex 解锁，那么在调用 pthread_cond_wait 后，其他线程就不能更改条件，条件就会一直不满足
2. 返回前再次锁 mutex 是为了保证线程从 pthread_cond_wait 返回后到再次条件判断前不被改变  

## 信号量

## 常见并发问题

### 非死锁缺陷

#### 违反原子性缺陷

##### 定义

违反了多次内存访问中预期的可串行性(即代码段的本意是原子的,但在执行中并没有强制实现原子性)

```c
1 Thread 1::
2 if (thd->proc_info) {
3 fputs(thd->proc_info, ...);
4 }
5
6 Thread 2::
7 thd->proc_info = NULL;
```

假如线程1在进入if语句后,调用fputs()前中断,然后线程2将proc_info置为空,然后线程1恢复运行,则会产生空指针异常.

解决方法: 给共享变量加锁

#### 违反顺序缺陷

##### 定义

两个内存访问的预期顺序被打破了(即A应该在B之前执行,但是实际运行并不是这个顺序)

```c
1 Thread 1::
2 void init() {
3 mThread = PR_CreateThread(mMain, ...);
4 }
5
6 Thread 2::
7 void mMain(...) {
8 mState = mThread->State;
9 }
```

如果线程1没有首先执行,那么mThread就没有初始化,线程2调用时就可能引发空指针异常

解决方法

加入条件变量或者信号量

```c
1 pthread_mutex_t mtLock = PTHREAD_MUTEX_INITIALIZER;
2 pthread_cond_t mtCond = PTHREAD_COND_INITIALIZER;
3 int mtInit = 0;
4
5 Thread 1::
6 void init() {
7 ...
8 mThread = PR_CreateThread(mMain, ...);
9
10 // signal that the thread has been created...
11 pthread_mutex_lock(&mtLock);
12 mtInit = 1;
13 pthread_cond_signal(&mtCond);
14 pthread_mutex_unlock(&mtLock);
15 ...
16 }
17
18 Thread 2::
19 void mMain(...) {
20 ...
21 // wait for the thread to be initialized...
22 pthread_mutex_lock(&mtLock);
23 while (mtInit == 0)
24 pthread_cond_wait(&mtCond, &mtLock);
25 pthread_mutex_unlock(&mtLock);
26
27 mState = mThread->State;
28 ...
29 }
```

### 死锁缺陷

#### 产生死锁的原因

1. 大型代码库中,组件之间会有复杂的依赖\
2. 封装,模块化与锁不是很契合

#### 产生死锁的条件

1. 互斥: 线程对于需要的资源进行互斥的访问(例如,一个线程抢到锁)
2. 持有并等待: 线程持有了资源(例如,已持有的锁),又在等待其他资源(例如,需要的锁)
3. 非抢占: 线程获得资源(例如,锁),不能被抢占
4. 循环等待: 线程之间存在一个环路,环路上每个线程都额外持有一个资源,而这个资源又是下一个线程要申请的.

四个条件同时满足,才会产生死锁

#### 解决方案

##### 预防

###### 循环等待

让代码不会产生循环等待

方法一: 全序(total ordering)  加入系统共有两个锁L1和L2,每次都先申请L1然后申请L2就可以避免循环等待. 缺点是复杂的系统中不适用

方法二: 偏序(partial ordering) 例如Linux中内存映射代码就使用了偏序锁,代码开头注释表明了10组不同的加锁顺序.

> 通过锁的地址来强制锁的顺序

###### 持有并等待

原子地抢锁

缺点: 不适合封装,因为不知道要抢哪些锁

###### 非抢占

trylock()函数尝试获得锁,若锁已被占有,则返回-1

```c
1 top:
2 pthread_mutex_lock(L1);
3 if (pthread_mutex_trylock(L2) != 0) {
4 pthread_mutex_unlock(L1);
5 goto top;
6 }
```

若另一个线程使用相同的加锁方式(L2然后L1),程序不会产生死锁,但是会产生活锁(系统一直在运行,但不会有进展)  
解决方法: 在循环结束的时候,先随机等待一个时间,再重复整个动作

问题: 封装无法保证返回开始处(goto top)

###### 互斥

无等待(wait-free)数据结构

例如使用CAS(比较并交换指令),不使用锁(但是可能存在活锁)

##### 通过调度避免死锁

CPU合理调度时间片,避免死锁

例如银行家算法,但是适用情景很局限

##### 检查和恢复

允许死锁发生,当死锁发生时再采取行动

例如数据库系统使用了死锁检测和恢复技术,死锁检测器定期运行,通过构建资源图来检查循环,当死锁发生是,系统需要重启,人工再进行复杂的修复操作

## 基于事件的并发  event-based concurrency

针对两方面问题: 一是多线程应用中,正确处理并发很有难度. 二是开发者无法控制多线程再某一时刻的调度.

当事件发生时,检查事件类型,然后处理事件

#### select()

select检查I/O描述符集合,分别查看它们中的某些描述符是否已经准备好读取,是否准备好写入,或有异常情况待处理.返回时,select()用请求操作准备好的描述符组成的子集替换给定的描述符集合,返回所有集合中就绪描述符的总数

**请勿阻塞基于事件的服务器**

缺陷是 如果事件请求发出I/O请求,那么服务器将会阻塞

### 异步I/O

这些接口使应用程序能够发出I/O请求,并在I/O完成之前立即将控制权返回给调用者,再通过另外的接口确定I/O是否完成(例如使用aio_error()来周期性poll(轮询)系统)

但是轮询太麻烦,一些系统提供了基于中断的方法,此方法使用UNIX信号(signal)在异步I/O完成时通知应用程序,从而消除了重复询问系统的需要

> ### UNIX信号
>
> 最简单的信号提供了一种与进程进行通信的方式.  
> 每个信号都一个名称,比如HUP(挂断),INT(中断),SEGV(段违规)等,当程序捕获信号时,会采取特定的行为来响应这种错误的程序行为,若是没有配置处理该信号的行为,一些默认行为就会生效
>
> 可以用kill命令行工具发送信号

### 状态管理

当事件处理程序发出异步I/O时,它必须打包一些程序状态,以便下一个事件处理程序在I/O最终完成时使用.

解决方案: 使用一种称为延续(continuation)的老编程语言结构. 基本上,在某些数据结构中记录完成处理该事件需要的信息,当事件发生时(磁盘I/O即将完成时),查找所需信息并处理事件.

### 缺点

多个CPU时,仍然会出现同步问题(例如临界区),必须采用通常的解决方案(比如锁).

# 持久性

## I/O设备

![image-20220904154326691](E:\笔记\操作系统导论.assets\image-20220904154326691.png)

采用这种分层架构的原因:

因为高性能的内存总线很短,没有足够的空间连接太多设备,这样设计可以让高性能设备(比如显卡)离CPU更进一些,低性能的设备离CPU远一些.同时外围总线可以连接大量的设备

![image-20220904154640093](E:\笔记\操作系统导论.assets\image-20220904154640093.png)

### 标准设备

![image-20220904154709627](E:\笔记\操作系统导论.assets\image-20220904154709627.png)

一个标准设备(不是真实存在的)包含两个部分,一: 向系统其他部分展现的硬件接口(interface). 二: 它的内部结构,包含设备相关的特定实现,比如芯片等等

### 标准协议

一个简化的设备接口包含3个寄存器: 状态(status)寄存器,可以读取并查看设备的状态; 命令(command)寄存器,用于通知设备执行某个具体任务; 数据(data)寄存器,将数据传给设备或从设备接收数据.

```c
While (STATUS == BUSY)
; // wait until device is not busy
Write data to DATA register
Write command to COMMAND register
(starts the device and executes the command)
While (STATUS == BUSY)
; // wait until device is done with your request
```

这个协议包含4步

1. 操作系统通过反复读取状态寄存器,等待设备进入可以接收命令的就绪状态,称之为轮询(poll)设备.
2. 操作系统下发数据到数据寄存器,如果主CPU参与数据移动,就称之为PIO(programmed I/O,与之相对的是DMA)
3. 操作系统将命令写入命令寄存器,这样设备就知道数据已经准备好了,它应该开始执行命令
4. 操作系统不断轮询设备,等待并判断设备是否执行完成命令

这个协议的好处是简单有效,但有些低效,比如轮询过程中比较低效

> DMA(Direct Memory Access,直接内存访问)与PIO(编程的I/O)
>
> - **PIO** 我们拿磁盘来说，很早以前，磁盘和内存之间的数据传输是需要CPU控制的，也就是说如果我们读取磁盘文件到内存中，数据要经过CPU存储转发，这种方式称为PIO。显然这种方式非常不合理，需要占用大量的CPU时间来读取文件，造成文件访问时系统几乎停止响应。
> - **DMA**  后来DMA（直接内存访问，Direct Memory  Access）取代了PIO，它可以不经过CPU而直接进行磁盘和内存（内核空间）的数据交换。在DMA模式下，CPU只需要想DMA控制器下达指令，让DMA控制器来处理数据的传送即可，DMA控制器通过系统总线来传输数据，传送完毕再通知CPU，这样就在很大程度上降低了CPU占用率，大大节省了系统资源，而它的传输速度与PIO的差异其实并不十分明显，因为这主要取决于慢速设备的速度。

### 中断减少CPU开销

使用中断,CPU不再需要轮询设备.而是向设备发出一个请求,然后让对应的进程休眠,切换执行其他任务,当设备完成了自身的操作,会抛出一个硬件中断,引发CPU跳转执行操作系统预先定义好的中断服务例程(Interrupt Service Routine,ISR),或更为简单的中断处理程序(interrupt handler)

> 中断处理程序是一小段操作系统代码,它会结束之前的请求(比如从设备读取到了数据或者错误码),并且唤醒等待I/O的进程继续执行.

![image-20220904161354894](E:\笔记\操作系统导论.assets\image-20220904161354894.png)

![image-20220904161403540](E:\笔记\操作系统导论.assets\image-20220904161403540.png)

使用中断并非总是最佳方案,倘若有个非常高性能的设备,在CPU第一次轮询时即可返回结果,如果还是用中断的方法,由于进程切换的开销,反而会使系统变慢.

此时应当使用混合策略,先尝试轮询一小段事件,如果设备没有完成操作,再使用中断. 这种两阶段(two-phased)的方法可以实现两种方法的好处

#### 网络中不要使用中断

如果每个包都发生一次中断,有可能导致操作系统发生活锁(livelock),即不断处理中断而无法处理用户层的请求.

若一个Web服务器因为点杠效应(Slashdot effect)而突然承受很重的负载,在这种情况下,偶尔使用轮询的方式可以更好的控制系统的行为,并允许Web服务器先服务一些用户请求,再回去检查网卡设备是否有更多的数据包到达.

> 点杠效应指的是当一个受众广泛的网站介绍了另一个小众的网站后，小众网站流量激增的现象。

#### 基于中断的优化-合并

设备在抛出中断之前,往往会等待一小段时间,在此期间,其他请求可能很快完成,因此多次中断可以合并为一次中断抛出,从而降低处理中断的代价,当然,等待太长会增加请求的延迟.

### DMA 直接内存访问

DMA引擎是系统中的一个特殊设备,它可以协调完成内存和设备间的数据传递,不需要CPU介入.

#### DMA工作过程

为了能够将数据传送给设备,操作系统会通过编程告诉DMA引擎数据在内存的位置,要拷贝的大小以及要拷贝到哪个设备. 在此之后,操作系统就可以处理其他请求.当DMA的任务完成后,DMA控制器会抛出一个中断告诉操作系统数据传输已完成

### 与设备交互的方法

#### 用明确的I/O指令

这些指令规定了操作系统将数据发送到特定设备寄存器的方法,从而允许构造上文提到的协议.例如x86中用in和out指令与设备进行交互.

这些指令通常是特权(privileged)指令,操作系统是唯一可以直接与设备交互的实体.

#### 内存映射I/O memory-mapped I/O

硬件将设备寄存器映射为内存地址,当需要访问设备寄存器中,操作系统读取或写入到该内存地址,硬件再将其转移到设备上,而不是内存上.

### 抽象设备接口

在最底层,操作系统的一部分软件清楚的知道设备如何工作,这部分软件称为设备驱动程序

例如Linux的文件系统栈,文件系统以及更上层不知道使用什么类型的磁盘,它只需要向下层的通用块设备层发送读写请求即可,块设备层再将这些请求路由给对应的磁盘驱动.![image-20220904164902264](E:\笔记\操作系统导论.assets\image-20220904164902264.png)

#### 不足之处

设备为了兼容大多数操作系统,不得不提供一个通用的接口,这样自身的特殊功能就无法使用.

例如使用SCSI设备的Linux,SCSI提供非常丰富的报告错误信息,但其他块设备(比如ATA/IDE)只提供非常简单的报错处理,这样上层的所有软件在出错时,只能收到一个通用的EIO错误码,SCSI提供的附加信息可能无法报告给操作系统.

## 磁盘驱动器

现代磁盘驱动器由大量扇区组成(512字节块)组成,可以进行多扇区操作,但是只有单个512字节的写入是原子的(即它将完整的完成,或根本不完成),如果发生掉电,则只能完成较大写入的一部分(称为不完整写入 torn write)

盘片: 一个圆形坚硬的表面,通过引入磁性变化来永久存储数据

数据在扇区的同心圆的每个表面上被编码,这样的同心圆称为一个磁道

### 单一磁道

![image-20220904225043061](E:\笔记\操作系统导论.assets\image-20220904225043061.png)![image-20220904225111883](E:\笔记\操作系统导论.assets\image-20220904225111883.png)

磁头等待期望的扇区旋转到磁头下,这一过程消耗的事件称为旋转延迟(rotational delay 或 rotation delay)

### 多磁道: 寻道时间

![image-20220904225236532](E:\笔记\操作系统导论.assets\image-20220904225236532.png)

与单磁道相比,多了寻道的过程

> 寻道指的是磁盘臂移动到正确的磁道

寻道,旋转是最昂贵的磁盘操作之一

当指定扇区经过磁盘磁头时,I/O的最后阶段将发生,称为传输(transfer),数据从表面读取或写入表面

### 缓存

缓存只是少量内存,驱动器可以使用这些内存来保存从磁盘读取或写入磁盘的数据.

### 后写缓存 write back

回写式（write back）即CPU只向Cache写入，并用标记加以注明，直到Cache中被写过的块要被进入的信息块取代时，才一次写入主存。这种方式考虑到写入的往往是中间结果，每次写入主存速度慢而且不必要。

其特点是速度快，避免了不必要的冗余写操作，但结构上较复杂。

### 直写 write through

直写式（write through），也叫写透，即CPU在向Cache写入数据的同时，也把数据写入主存以保证Cache和主存中相应单元数据的一致性。

其特点是简单可靠，但由于CPU每次更新时都要对主存写入，速度必然受影响。

### I/O时间

主要有两种工作: 随机工作负载 和 顺序工作负载

1. 随机和顺序工作负载之间的驱动性能差距很大
2. 高端性能驱动器与低端容量驱动器之间性能差距很大

### 磁盘调度

### SJF: 最短任务优先

与任务调度不同,每个任务的长度是未知的,而对于磁盘调度,可以猜测磁盘请求需要多长时间.通过估计请求的查找和可能的旋转延迟,磁盘调度程序可以知道每个请求将花费多长时间,因此选择先服务花费最少时间的请求 即 遵循**SJF(最短任务优先)**的原则

#### SSTF: 最短寻道时间优先

即选择最近磁道上的请求,但是操作系统无法利用驱动器的几何结构,只能看到一系列的块,基于此,操作系统可以简单的实现最近块优先(Nearest-Block-First,NBF)

**可能存在饥饿问题**

#### 电梯(又称 SCAN或C-SCAN)

将一次跨越磁盘称为扫一遍,如果请求的块所属的磁道在这次扫一遍中已经服务过了,它就不会立即处理,而是排队等待下一扫一遍

变种1: F-SCAN 扫一遍时冻结队列以进行维护,将扫一遍期间进入的请求放入到队列中,一遍稍后处理,这样做可以避免远距离请求饥饿,延迟了迟到了但更近的请求

变种2: C-SCAN 循环SCAN(Circular SCAN)不是在一个方向扫过磁盘,而是从外圈扫到内圈,从内圈扫到外圈,也称为电梯算法

#### SCAN(甚至SSTF)没有严格遵循SJF

忽视了旋转

#### SPTF: 最短定位时间优先

**视旋转与寻道相比的相对时间**而定

现代驱动器中,查找与旋转大致相当,但是SPTF在操作系统中实现更加困难,操作系统通常不太清楚磁道的边界在哪,也不知道磁头当前的位置(旋转到了哪里),因此SPTF通常在驱动器内部执行.

### 其他调度问题

#### I/O合并

例如请求块33和块34,应合并为1个请求,可以减少发送到磁盘的请求数量,从而减低了开销

#### 工作保全(work-conserving)与非工作保全(non-work-conserving)

工作保全: 即使有一个I/O请求,也应立即向驱动器发出请求

非工作保全: 有时最好等待一段时间

## 廉价冗余磁盘阵列 RAID 

使用多个磁盘,内存以及一个或多个处理器来管理系统.

好处: 

1. 性能高,因为可以并行使用多次磁盘
1. 容量大
1. 可以提高可靠性,通过某种形式的冗余,RAID可以允许损失一个磁盘并保持运行

### RAID 0级: 条带化

### RAID 1级: 镜像

### RAID4级: 通过奇偶校验节省空间

### RAID5级: 旋转奇偶检验

### 总结

条带: 性能高,可靠性差

镜像: 随机I/O性能高,可靠性好

RAID-5: 容量高,可靠性好,顺序执行I/O性能好,小写入性能较差

## Linux 文件和目录 相关API

存储虚拟化形成了两个关键的抽象

一个是文件(file).文件就是一个线性字节数组,每个文件都有某种低级名称(low-level-name),通常称为inode号,每个文件都有一个与之关联的inode号

第二个是目录(directory).一个目录,也有一个低级名字(inode号),当内容非常具体:  它包含一个(用户可读的名字,低级名字)set的列表

> 假设存在一个inode号为10的文件,它的用户可读名字为 "foo",则"foo"所在的目录会有个列表,其中有条目("foo",10).

目录中每个条目都指向文件或其他目录

名称在系统中非常重要,因为访问任何资源的第一步是能够命名它

### open()

```c
int fd = open("foo",O_CREATE | O_WRONGLY | O_TRUNC);	
```

其中O_CREATE表示 只能写入该文件, O_WRONGLY表示只能以这种方式(O_WRONGLY)打开, O_TRUNC表示若该文件存在,则首先将其截断为0字节大小,删除所有现有内容

open()的返回值是文件描述符

### 文件描述符

文件描述符是一个整数,**是每个进程私有的**

0表示标准输入(进程可以读取以接受输入)  
1表示标准输出(进程可以写入以便将信息显示到屏幕)  
2表示标准错误(进程可以写入错误信息)

因此当第一次打开一个文件时,它的文件描述符几乎肯定是3

### 写入文件

首先打开一个文件准备写入open(),然后调用write()系统调用,对于较大的文件,可能重复调用,然后close()

### 读取和写入,但不按顺序

有时能够读取或写入文件中的特定偏移量是由于的.例如,如果在文本文件中创建了索引,并利用它来查找特定单词,最终会从文件中的某些随机偏移量中读取数据

比如lseek()

注意: 调用lseek()与移动磁盘臂的磁盘的寻道操作无关,对lseek()的调用只是改变内核中变量的值

### fsync()

大多数时候,程序调用write后,并不会立即写入磁盘中,出于性能原因,文件系统会将这些写入在内存缓冲(buffer),一段时间后再将写入发送到存储设备.

当进程针对特定文件描述符调用fsync()时,文件系统强制将所有脏数据写入磁盘响应

### 文件重命名

> mv foo bar

mv命令,将文件的新版本写入临时名称,再使用fsync()强制写入磁盘

### 获取文件信息

文件系统能够保存关于它正在存储的每个文件的大量信息,我们通常将这些数据称为文件元数据(metadata). 可以同过stat()或fstat()系统调用查看特定文件的元数据.

```c
struct stat {
    dev_t st_dev; // ID of device containing file
    ino_t st_ino; // inode number
    mode_t st_mode; // protection
    nlink_t st_nlink; // number of hard links
    uid_t st_uid; // user ID of owner
    gid_t st_gid; // group ID of owner
    dev_t st_rdev; // device ID (if special file)
    off_t st_size; // total size, in bytes
    blksize_t st_blksize; // blocksize for filesystem I/O
    blkcnt_t st_blocks; // number of blocks allocated
    time_t st_atime; // time of last access
    time_t st_mtime; // time of last modification
    time_t st_ctime; // time of last status change
};
```

```
tiger@tiger:~$ stat bar2 
  File: bar2
  Size: 6         	Blocks: 8          IO Block: 4096   regular file
Device: 803h/2051d	Inode: 5252919     Links: 1
Access: (0664/-rw-rw-r--)  Uid: ( 1000/   tiger)   Gid: ( 1000/   tiger)
Access: 2022-09-05 19:03:16.641658453 +0800
Modify: 2022-09-05 19:03:12.685804854 +0800
Change: 2022-09-05 19:23:04.709024267 +0800
Birth: 2022-09-05 19:03:12.685804854 +0800

```

每个文件系统通常会将这种类型的信息保存在一个名为inode的结构中.

### 删除文件

rm,底层中,rm使用unlink()来删除文件

### 创建目录

mkdir

创建一个空目录时,有两个条目: 一个引用自身的条目(称为"."),一个引用其父目录的条目(称为"..")

可以用ls -a查看这些目录

![image-20220905194429836](E:\笔记\操作系统导论.assets\image-20220905194429836.png)

### 读取目录

不是像打开文件一样打开一个目录,而是使用一组新的调用

下面是打印目录内容的示例程序

```c
int
main (int argc, char *argv[])
{
  DIR *dp = opendir (".");
  assert (dp != NULL);
  struct dirent *d;
  while ((d = readdir (dp)) != NULL)
    {
      printf ("%lu %s\n", (unsigned long)d->d_ino, d->d_name);
    }
  closedir (dp);
  return 0;
}
```

```c
struct dirent {
    char d_name[256]; // filename
    ino_t d_ino; // inode number
    off_t d_off; // offset to the next dirent
    unsigned short d_reclen; // length of this record
    unsigned char d_type; // type of file
};
```

目录只有少量信息,基本上是将名称映射到inode号,以及少量细节

### 删除目录

rmdir(),rmdir()要求该目录在被删除之前是空的(只有"."和".."目录),如果尝试删除非空目录,调用就会失败

### **硬链接** 

ln命令

文件系统中创建新条目实际上是使用link()系统调用. link()有两个参数: 一个旧路径名和一个新路径名

```
prompt> echo hello > file
prompt> cat file
hello
prompt> ln file file2
prompt> cat file2
hello
```

#### link()本质

link()只是在要创建链接的目录中创建了另一个名称,并将其指向原有文件的相同inode号,该文件不以任何方式复制,可以看见,使用ls -i打印出每个文件的inode号都是相同的.

```
tiger@tiger:~/var$ ls -i
6303340 test1  6303340 test2
```

### 创建文件的过程

首先构建一个结构(inode),它将跟踪几乎所有关于文件的信息,包括其大小,文件块在磁盘上的位置等等.其次,将用户可读的名称链接到该文件,并将该文件放入到目录中.

### unlink()

当调用unlink()时,它检查inode号中引用次数,该引用次数(又称链接技术,link count)允许文件系统跟踪有多少不同的文件名已链接到这个inode. unlink()会删除人类可读的名称(正在删除的文件)与给定inode号的链接,并减少引用次数,当引用次数为0时,文件系统才会释放inode和相关数据块.

> 使用stat命名可以查看引用次数
>
> ```
> tiger@tiger:~/var$ stat test1
>   File: test1
>   Size: 6         	Blocks: 8          IO Block: 4096   regular file
> Device: 803h/2051d	Inode: 6303340     Links: 2
> Access: (0664/-rw-rw-r--)  Uid: ( 1000/   tiger)   Gid: ( 1000/   tiger)
> Access: 2022-09-05 20:03:04.231329398 +0800
> Modify: 2022-09-05 20:03:02.563304266 +0800
> Change: 2022-09-05 20:03:02.567304326 +0800
>  Birth: 2022-09-05 20:02:27.950781823 +0800
> ```

### 符号链接 (软链接)

ln -s 命令

#### 与硬链接的区别

符号链接本身实际上一个不同类型的文件. 类型为: symbolic link

```
tiger@tiger:~/var$ ln -s test1 testS
tiger@tiger:~/var$ stat testS
  File: testS -> test1
  Size: 5         	Blocks: 0          IO Block: 4096   symbolic link
Device: 803h/2051d	Inode: 6303339     Links: 1
Access: (0777/lrwxrwxrwx)  Uid: ( 1000/   tiger)   Gid: ( 1000/   tiger)
Access: 2022-09-05 20:20:18.226469228 +0800
Modify: 2022-09-05 20:20:18.226469228 +0800
Change: 2022-09-05 20:20:18.226469228 +0800
Birth: 2022-09-05 20:20:18.226469228 +0800
```

符号链接的大小随着路径名增大而增大

#### 可能造成悬空引用

删除原始文件会导致符号链接指向不再存在的路径名

```
tiger@tiger:~/var$ rm test1 test2
tiger@tiger:~/var$ cat testS 
cat: testS: No such file or directory
```

### 挂载

使用mount 将文件系统挂载到挂载点上,可以将所有文件系统统一到一颗树上,而不是拥有多个独立的文件系统

### 软硬链接

硬链接的局限性在于它们不能指向目录(因为害怕文件夹系统层次结构中的循环),并且只能指向同一卷的文件(即inode号必须仍然有意义)

符号链接允许用户为系统上的任何其他文件或目录创建别名

#### 个人理解

硬链接相当于为文件创建一个别名,并在文件的引用次数+1

软链接相当于对文件的引用(类似指针),当源文件不存在时,这个引用也会失效

## 文件系统的实现 VSFS (Very Simple File System)

### 磁盘分块

## 局部性和快速文件系统

老UNIX文件系统效率较低,因为文件存在位置彼此之间没有关联,定位成本昂贵  
另一个原因是原始块大小太小(512字节),从磁盘传输的角度来说是低效的(需要频繁定位),好处是最大限度地减少了内部碎片

### FFS (Fast File System) 快速文件系统

#### 更改磁盘上的结构

FFS将磁盘划分为一些分组,称为柱面组,Linux ext2和ext3称之为块组(block group)

在同一组中放置相关的文件,先后访问两个文件不会导致跨越磁盘长时间的寻道

出于可靠性原因,每个组中都有超级块(super block)的一个副本,像往常一样,每个柱面组的大部分都包含数据块

#### 分配文件和目录

##### 目录

找到分配数量少的柱面组(目的是跨组平衡目录)和大量自由inode,并将目录数据和inode放在该分组

##### 文件

将文件的数据块分配到与其inode相同的组中,从而防止inode和数据之间的长时间寻道,其次,将同一目录中的所有文件放在它们目录的柱面组中

#### 大文件

将大文件分成大块放入到不同的块组中

磁盘上分散文件块会损害性能,但是如果大块大小足够大,大部分时间仍然花在从磁盘传输数据上,而在大块之间寻道的时间较少.

每次开销做更多的工作,从而减少开销,这个过程就称为摊销.

### Other

#### 子块

引入子块来解决小文件传输的问题,但是效率低下,通过缓冲写入,再以4KB块的形式将它们发送到文件系统.

#### 优化磁盘布局

![image-20220906191232232](E:\笔记\操作系统导论.assets\image-20220906191232232.png)

例如,连续读取块0和块1是,当读取完块0时,块1已经旋转

通过不同的磁盘布局,跳过某些块

现代磁盘在内部读取整个磁道并将其缓冲在内部磁盘中间

### 原子rename()操作

