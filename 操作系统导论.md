# CPU

## 第六章 机制：受限直接执行

### 虚拟化CPU以实现共享物理CPU

#### 问题一：性能，如何在不增加开销的情况下实现虚拟化

#### 问题二：控制权，如何有效的运行进程，同时保留对CPU的控制权

### 受限直接执行（LDE）limited direct execution

#### 问题一：受限制的操作

例如发出I/O请求或获得更多系统资源

解决：通过陷阱（trap）指令进入内核模式，完成受限操作后再调用从陷阱返回指令（return-from-trap）返回用户模式。

x86执行陷阱时，处理器将程序计数器、标志和其他一些寄存器推送到每个进程的内核栈（kernel stack）上。从返回陷阱将从栈弹出这些值，并恢复执行用户模式程序。

内核在启动时设置陷阱表（trap table）来实现。

LDE协议有两个阶段。第一个阶段（在系统引导时），内核初始化陷阱表。第二个阶段（运行进程时），在使用陷阱返回指令，开始执行进程之前，内核设置一些内容（例如，在进程列表中分配一个节点，分配内存）。然后CPU切换到用户模式并开始执行该进程。当进程希望发出系统调用时，会重新切换为内核模式，然后再通过返回陷阱指令返回，该进程继续执行，并从main()返回。OS清理干净，任务结束。

#### 问题二：在进程之间切换

关键：如何重获CPU的控制权

1.等待系统调用（可能进入无限循环）

2.操作系统进行控制（使用硬件提供的时钟中断功能）

时钟中断时，硬件要为正在运行的程序保存足够的状态。

##### 保存和恢复上下文：

存在两种寄存器保存/恢复。

第一种是发生时钟中断时，运行进程的用户寄存器由硬件隐式保存，使用该进程的**内核栈**。

第二种是操作系统决定从A切换到B，此时内核寄存器被软件（OS）明确的保存，但存储在该进程的**进程结构**的内存中。

总过程：进程A正在运行，然后被中断时钟中断。硬件保存它的寄存器（在内核栈中），并进入内核。操作系统决定切换到进程B。此时调用switch()例程，该例程仔细保存当前寄存器的值（保存到A的进程结构），恢复寄存器进程B（从进程结构B中），然后切换上下文，即通过改变栈指针来是使用B的内核栈。最后操作系统从陷阱返回，恢复B的寄存器，并运行它。

## 第七章 进程调度：介绍

周转时间：任务完成时间减去任务到达系统的时间

响应时间：任务到达系统首次运行的时间

### 先进先出（FIFO，First In First Out）

### 最短任务优先（SJF，Shortest Job First）

假设所有任务同时到大，SJF是最优的调度算法。但若是一个长任务先到达，周转时间将变长。

### 最短完成时间优先（STCF，Shortest Time-to-Completion First）

向SJF添加抢占，每当新工作进入系统时，它就会确定剩余工作和新工作谁的剩余时间更少，然后调度该工作。

假设工作可以随时到达，则STCF是最优的

### 轮转（RR，Round-Robin）

在一个时间片内运行一个工作，然后切换到任务队列的下一个工作。

响应时间大大减少。

时间片的长度必须是时钟中断周期的倍数。需要权衡时间片的长度，以便摊销上下文切换的成本。

上下文切换的成本不仅仅包括，来自保存和恢复少量寄存器的操作系统操作，还在CPU高速缓存、TLB、分支预测器和其他片上硬件中建立了大量的状态，切换到另一个工作将会导致此状态刷新。

任何公平的策略，即在小规模的时间内将CPU均匀分配到活动进程之间，在周转时间这类指标上表现不佳。

**第一种：SJF、STCF优化周转时间，但对响应时间不利。**

**第二种：RR优化响应时间，但对周转时间不利。**

考虑到IO操作，应该实现重叠（即在一个进程在阻塞等待IO操作时，CPU调度到另一个进程以节约CPU资源）。

### **如何知道每个工作的长度？**

## 第八章 调度：多级反馈队列

### 多级反馈队列（MLFQ，Multi-level Feedback Queue）

解决了两方面问题：1、优化周转时间。2、降低响应时间。

基本规则：MLFQ中存在许多独立的队列，每个队列有不同的优先级，任何时刻，一个工作只能存在于一个队列中。MLFQ总是执行执行较高的优先级的工作。在一个队列中，采用轮转调度。

#### 规则一

如果A的优先级>B的优先级，运行A（不运行B）。

#### 规则二

如果A的优先级=B的优先级，轮转运行A和B。

#### 规则三

工作进入系统时，放在最高优先级（最上层队列）。

#### 规则四

一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次CPU），就降低其优先级（移入低一级队列）。

#### 规则五

经过一段时间S，就将系统中所有工作重新加入最高优先级队列。

#### 特点

不需要预先知道任务的运行时间，而是观察任务的运行来给出对应的优先级。对于短时间的交互型工作，获得类似SJF/STCF的很好的全局性能，同时对于长时间运行的CPU密集型负载也可以公平地，不断地稳步向前。

## 第九章 调度：比例份额

### 基本概念：彩票（ticket）数代表份额

### 彩票机制

1、用户内部用自己货币，再根据货币给各个任务分发彩票

2、彩票转让，常见于客户端/服务端交互，客户端转让彩票给服务端，服务端执行结束后会将这部分彩票归还给客户端

3、彩票通胀：一个进程可以临时提升或降低自己拥有的彩票数量，可用于进程之间相互信任的环境

### 实现

使用列表来记录系统中所用进程，以及彩票的总数。

假设有A、B、C三个进程，每个进程有一定数量彩票。

做出调度决策前，从彩票总数400中选择一个随机数，假设为300，然后遍历链表，用一个计数器找到中奖者。代码从前向后遍历链表，将每张票的值加到`counter`上，直到值超过`winnner`。

为使过程更有效率，建议将列表项按照彩票数递减排序，能保证使用最小的迭代次数找到节点。

![image-20220726203459202](C:\Users\98449\AppData\Roaming\Typora\typora-user-images\image-20220726203459202.png)

```c
// counter: used to track if we’ve found the winner yet
int counter = 0;
// winner: use some call to a random number generator to
// get a value, between 0 and the total # of tickets
int winner = getrandom(0, totaltickets);
// current: use this to walk through the list of jobs
node_t *current = head;
while (current) {
  counter = counter + current->tickets;
  if (counter > winner)
    13 break; // found the winner
  current = current->next;
}
// ’current’ is the winner: schedule it...
```

### 公平性

当工作执行很短时，平均不公平度差，只有当工作执行非常多的时间片时，彩票调度才能得到期望的结果。

### 如何分配彩票？（没有最佳答案）

### 随机性优化

在工作运行时间很短时，不能产生正确的比例。

Waldspurger提出步长调度。

##### 步长调度

系统中每个工作都有自己的步长，这个值与票数值成反比。在上面的例子中，A、B、C这3个工作的票数分别是100、50和250，我们通过一个大数分别除以他们的票数来获得每个进程的步长。比如用10000除以这些票数值，得到3个进程的步长分别为100、200和40。我们称这个值为每个进程的步长（stride）。每次进程运行后，我们会让它的计数器（称为行程(pass)）来增加它的步长，记录它的总体进展。

基本思路：当需要进行调度时，选择拥有最小行程值的进程，并且在运行之后，将该进程的行程值加一个步长。

Waldspurger给出的伪代码

```c
current = remove_min(queue); // pick client with minimum pass
schedule(current); // use resource for quantum
current->pass += current->stride; // compute next pass using stride
insert(queue, current); // put back into the queue
```

在我们的例子中，3 个进程（A、B、C）的步长值分别为100、200 和40，初始行程值都为0。因此，最初，所有进程都可能被选择执行。假设选择A（任意的，所有具有同样低的行程值的进程，都可能被选中）。A 执行一个时间片后，更新它的行程值为100。然后运行B，并更新其行程值为200。最后执行C，C 的行程值变为40。这时，算法选择最小的行程值，是C，执行并增加为80（C 的步长是40）。然后C 再次运行（依然行程值最小），行程值增加到120。现在运行A，更新它的行程值为200（现在与B 相同）。然后C 再次连续运行两次，行程值也变为200。此时，所有行程值再次相等，这个过程会无限地重复下去。

![image-20220726212456093](C:\Users\98449\AppData\Roaming\Typora\typora-user-images\image-20220726212456093.png)

#### 优点

实现精确控制

#### 缺点

需要设置一个全局状态，而彩票调度不需要。假如一个新的进
程在上面的步长调度执行过程中加入系统，应该怎么设置它的行程值呢？设置成0 吗？这样的话，它就独占CPU 了。

此彩票调度算法能够更合理地处理新加入的进程。

# 内存

## 内存交换

当访问超出物理内存大小时，需要在页表结构添加额外信息，比如增加一个存在位（present bit，或者其他类似机制），告诉我们页是否在内存中，如果不存在，则操作系统页错误处理程序会运行以处理页错误，从而将需要的页从硬盘读取到内存，可能还要先换出内存中的一些页，为即将换入的页腾出空间。

### 交换空间

在硬盘中开辟一部分用于物理页的移入与移出，这样的空间称为交换空间（如Linux的swap分区，Windows的虚拟内存）。

### 存在位

存在位设置为1，表示该页存在于物理内存中，设置为0，表示该页在磁盘中。

### 页错误

访问不在物理内存中的页，这种行为被称为页错误（page fault）。

在页错误时，操作系统被唤起处理页错误，一段称为“页错误处理程序”（page-fault handler）的代码会执行。

PS：之所以称为错误是因为，当发生这种情况时，硬件将控制权交回给操作系统，硬件能做的就是触发异常，这与进程执行非法操作处理流程一样，所以称为错误。

#### 为什么硬件不能处理页错误

1、页错误导致的硬盘操作很慢，即使操作系统需要很长时间来处理故障，执行大量指令，但相比于硬盘操作，这些额外开销很小。

2、如果要处理这些故障的话，硬盘必须了解交换空间，如何向硬盘发起I/O操作，等等。由于性能和简单的原因，所以不进行处理。

#### TLB未命中

```c
1 VPN = (VirtualAddress & VPN_MASK) >> SHIFT
2 (Success, TlbEntry) = TLB_Lookup(VPN)
3 if (Success == True) // TLB Hit
4 if (CanAccess(TlbEntry.ProtectBits) == True)
5 Offset = VirtualAddress & OFFSET_MASK
6 PhysAddr = (TlbEntry.PFN << SHIFT) | Offset
7 Register = AccessMemory(PhysAddr)
8 else
9 RaiseException(PROTECTION_FAULT)
10 else // TLB Miss
11 PTEAddr = PTBR + (VPN * sizeof(PTE))
12 PTE = AccessMemory(PTEAddr)
13 if (PTE.Valid == False)
14 RaiseException(SEGMENTATION_FAULT)
15 else
16 if (CanAccess(PTE.ProtectBits) == False)
17 RaiseException(PROTECTION_FAULT)
18 else if (PTE.Present == True)
19 // assuming hardware-managed TLB
20 TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits)
21 RetryInstruction()
22 else if (PTE.Present == False)
23 RaiseException(PAGE_FAULT)
```

有3种重要情景。  
1、该页存在且有效（第18-21行），在这种情况下，TLB未命中处理程序可以简单的冲PTE中获取PFN，然后重试指令（这次TLB会命中）  
2、该页不在内存中，运行页错误处理程序（第22-23行）  
3、访问无效页，操作系统陷阱处理程序运行，可能会杀死非法进程（第13-14行）

### 高低水位线

大多数操作系统会设置高水位线（High Watermark），低水位线（Low Watermark），当操作系统发现少于LW个页可用时，后台分则释放内存的线程会开始运行，知道有HW个可用的物理页。这个后台线程称为交换守护进程或页守护进程，完成任务后进入休眠状态。

## 内存替换策略

### 最优替换策略(optimal)

替换内存中在最远将来才会被访问到的页，但是实现不了。  

### 缓存未命中的类型

#### 强制性未命中(compulsory miss)

又称为冷启动未命中，因为缓存一开始是空的，这是对项目的第一次引用。

#### 容量未命中(capacity miss)

缓存的空间不足而不得不踢出一个项目以将新项目引入缓存。

#### 冲突未命中(conflict miss)

这种未命中出现在硬件中，因为硬件缓存中对项的放置位置有限制，这是由于所谓的集合关联性。它不会出现在操作系统页面缓存中，因为这样的缓存总是完全关联的，即对页面放置的内存位置没有限制。

冲突未命中（conflict miss) 和缓存的实现方式有关。大多数缓存，尤其是硬件缓存，由于它们需要设计的较为简单，因此限制了**块**可以被放置的位置。例如 block i 只能放在 block (**i mod cache size**) 的地方，以上图为例，缓存的大小为4，如果要取 block 8的数据，则只能放在缓存的第0块，同样，block 9 放在缓存的 block  1处。因此，如果要取的块为 block 0， block 4，block 8，那么计算出来都应该放在缓存 block 0的位置，因此放  block 4时，会覆盖原来 block 0的数据，加入需要循环的访问 block 0，block 8，block 0，block  8，这样就会一直不能命中，即使缓存有多余的空间，但位置的限制导致一直覆盖缓存上 block 0 的数据，造成**冲突未命中**。![image-20220830195516083](E:\笔记\操作系统导论.assets\image-20220830195516083.png)

### FIFO 先入先出

### 随机策略

### LRU 最近最少使用

基于局部性原则（时间，空间局部性）  
在大多数情况下，这种策略效果不错

### 各个策略特点

1、当工作负载不存在局部性时，使用的策略区别不大。 ![image-20220830203301410](E:\笔记\操作系统导论.assets\image-20220830203301410.png)
2、80-20负载场景（80%的引用是访问20%的热门页，20%的引用时剩余80%的冷门页），尽管随机和FIFO都很好的运行，但LRU更好 ![image-20220830203211186](E:\笔记\操作系统导论.assets\image-20220830203211186.png) 
3、循环顺序负载，依次引用50个页，从0开始，然后是1，...，49，然后循环  
在许多应用程序（如数据库)中非常常见，LRU和FIFO最差。这些算法在循环顺序的工作负载下，踢出较久的页。即使缓存的大小是49页，50个页面的循环连续负载也会导致0%的命中率。随机策略效果明显更好。  
![image-20220830203233492](E:\笔记\操作系统导论.assets\image-20220830203233492.png)

### LRU如何实现

有一种方法，在页表中保存时间字段，但是不可行，这样的话每次踢出页都要遍历页表。

### 近似LRU

硬件添加一个使用位（use bit，有事称为引用位 reference bit），每当页被引用时，硬件将使用位 置于1，但是硬件不会清除使用位（由操作系统负责） 

Corbato时钟算法：时钟指针开始时指向某个特定的页，当要进行页替换时，操作系统检查当前指向的页P的使用位是1还是0，如果是1，则将使用位置于0，时钟指针递增到下一页（P+1），直到找到一个使用位为0的页。最坏的情况是遍历一次页表，具有不重复扫描内存来寻找未使用页的特点

下图真是时钟算法的一个变种行为：在需要进行页替换时随机扫描各页，如果遇到一个页的引用位为1，就将该位设置为0，直到找到一个使用位为0的页，将这个页替换。  
![image-20220830203539166](E:\笔记\操作系统导论.assets\image-20220830203539166.png)

### 脏页

如果页已被修改并因此变脏，则踢出它必须把它写入磁盘，代价很昂贵。如果它没被修改，踢出就没成本，物理帧可以简单地重用于其他目的而无须额外的I/O，因此，一些虚拟机系统更倾向与踢出干净页。

为了支持这种行为，硬件应该包括一个修改位（modified bit，又名脏位，dirty bit），每次写入页时都会设置此位。例如时钟算法可以改动，以扫描即未使用又干净的页先踢出。

### 其他虚拟内存策略介绍

#### 预取（prefetching）

操作系统预测一个页面即将被使用，从而提前载入，这种行为称为预取，例如代码页P被载入内存，那么代码页P+1也很有可能被载入

#### 聚集写入、分组写入（clustering,grouping）

许多系统会在内存中收集一些待完成写入，并以一种更高效的写入方式将它们写入磁盘，这种行为称为聚集写入，或者就是分组写入

### 抖动

正在运行的进程内存需求超过了可用物理内存，在这种情况下，系统将不断地进行换页，这种行为称之为抖动（thrashing）

#### 解决方法一：准入控制

系统不运行部分进程，希望减少进程的工作集能放入内存

#### 解决方法二：杀死进程

### 扩展：ARC算法，类似LRU，但避免LRU的最坏情况行为

## VAX/VMS虚拟内存系统

### 内核映射

![image-20220831224607905](E:\笔记\操作系统导论.assets\image-20220831224607905.png)

在上下文切换时，操作系统改变P0和P1寄存器以指向即将运行的进程的适当页表，但是不改变**S基址和界限寄存器**，以此达到将“相同的”内核结构映射到每个用户的地址空间  
如果内核完全位于物理内存中，那么将页表的交换页切换到磁盘是非常困难的。如果内核被赋予了自己的地址空间，那么在用户程序和内核之间移动数据将变的复杂，通过这种构造（**现在广泛使用**）内核几乎就像应用程序库一样。

### 页替换

没有使用引用位，使用分段FIFO的策略

#### 分段FIFO

每个进程都有一个可以保存在内存中的最大页数，称为驻留页大小（Resident Set Size,RSS）。每个页都保存在FIFO列表中，当一个进程超过RSS时，先入的页被驱逐，**不需要任何硬件支持**

##### 二次机会列表（second-chance-list）

纯粹的FIFO不是很好，为了提升FIFO的性能，引入两个二次机会列表（second-chance-list）,页在从内存中被踢出之前被放在其中，具体来说是全局的干净页空闲列表和脏页列表。当进程P超过其RSS时，将从其每个进程的FIFO中移除一个页。如果页是干净的，则将其放在干净页列表的末尾。如果页是脏的，则将其放在脏页列表的末尾。  
如果另一个进程Q需要一个空闲页，它会从全局干净列表中取出第一个空闲页。但是如果原来的进程P在回收之前在该页上出现页错误，则P会从空闲（或脏）列表中回收，从而避免昂贵的磁盘访问。这些全局二次机会列表越大，分段的FIFO算法就越接近LRU。

### 页聚集

对页分组，执行更少和更大的写入，从而提高性能。（因为磁盘在大型传输中效果更好，较减少了寻道时间）

### 按需置零（demand zeroing）

常规做法：  
地址空间添加一个页的例子：在一个初级实现中，操作系统响应一个请求，在物理内存中找到页，将页添加到堆中，并将之置零，然后将其映射到地址空间中（设置页表以根据需要引用该物理页）。在页没有被进程使用时，代价很昂贵。

按需置零：  
当页添加到地址空间时，操作系统的工作很少。它会在页表中放入一个标记 页不可访问的 条目。如果进程读取或写入页，则向操作系统发送**陷阱**。在处理页时，操作系统注意到（通常通过页表项中“保留的操作系统字段”部分标记的一些位），这是一个按需置零页。之后，操作系统再完成寻找物理页的必要操作，将它置零，并映射到进程的地址空间。

好处：在进程不访问此页的时候，这些操作就可以避免。属于惰性操作。

### 写入时复制（copy-on-write）

如果操作系统需要将一个页面从一个地址空间复制到另一个地址空间，不是实际复制它，而是将其映射到目标地址空间，并在两个地址空间中将其标记为已读。如果两个地址空间都只读取页面，则不会采取进一步操作，实现了快速复制而不实际移动任何数据。

但是，如果其中一个地址空间确实尝试写入页面，就会陷入操作系统。操作系统会注意到该页面是一个COW页面，因此惰性地分配一个新页，填充数据，并将这个新页映射到错误处理的地址空间，然后继续。

#### fork()和exec()和COW

fork()会创建调用者地址空间的精确副本，对于大的地址空间，这样的复制过程很慢，并且是数据密集的。通常，大部分的地址空间会被随后的exec()调用立即覆盖，它用即将执行的程序覆盖进程的地址空间。  
通过使用写时复制的fork()，避免了大量不必要的复制。（一开始调用fork()的时候，只是快速复制，只有在写入的时候，才真正的创建新页写入）

# 并发

## 线程与进程

每个线程类似于独立的进程，只有一点区别，**它们共享地址空间**，从而能够访问相同的数据

线程之间的上下文切换类似于进程间的上下文切换，对于进程，我们将状态保存到进程控制块（Process Control Block，PCB）。对于线程，保存到线程控制块（Thread Control Block，TCB）。  
线程与进程的上下文切换有一点主要区别，地址空间保持不变（即不需要切换当前使用的页表）

另一个主要区别在于栈。![image-20220901201342881](E:\笔记\操作系统导论.assets\image-20220901201342881.png)   


左图为传统进程地址空间模型（单线程进程），只有一个栈，通常位于地址空间的底部  
右图为多线程的进程地址空间模型，**每个线程都有一个栈**，右图中，可以看到两个栈跨越了进程的地址空间。  
所有位于栈上的变量、参数、返回值和其他放在栈上的东西，将被放置在有时称为线程本地（thread-local）存储的地方，即相关线程的栈。

运行时，每个线程都有自己的专用寄存器

### 关键并发术语

#### 临界区

临界区（critical section）是访问共享资源的一段代码，资源通常是一个变量或数据结构

#### 竞态条件

竞态条件（race condition）出现在多个执行线程大致同时进入临界区时，它们都试图更新共享的数据结构，导致了非期望的结果

#### 不确定性

不确定性（indeterminate）程序由一个或多个竞态条件组成，程序的输出因运行而异，具体取于哪些线程在何时运行，这导致结果是不确定的（deterministic）

#### 互斥执行

为了避免这些问题，线程应该使用某种互斥（mutual exclusion）原语，这样可以保证只有一个线程进入临界区，从而避免出现竞态，并产生确定的程序输出。

#### 原语

原语是指由若干条机器指令构成的，并用以完成特定功能的一段程序。这段程序在执行期间是不可分割的。其主要特点是不可分割性。

## 锁

### 评价锁

#### 互斥

锁是否有效？

#### 公平性

当锁可用时，是否每一个竞争线程有公平的机会抢到锁？是否有竞争锁的线程会饿死？

#### 性能

没有竞争时，只有一个线程抢锁，释放锁的开支如何？一个CPU上多个线程竞争，性能如何？多个CPU，多个线程竞争时的性能？

### 控制中断

临界区关闭中断  
优点：简单  
缺点：这种方法允许所有调用线程执行特权操作（打开关闭中断），恶意程序可能独占CPU，只能重启系统  
		   不支持多处理器，当位于不同CPU的线程试图进入临界区时，关闭中断没有作用  
		   效率低

### 自旋

### 测试并设置指令（test-and-set-instruction）

```c
int
TestAndSet (int *old_ptr, int new)
{
  int old = *old_ptr; // fetch old value at old_ptr
  *old_ptr = new;     // store ’new’ into old_ptr
  return old;         // return the old value
}

typedef struct lock_t
{
  int flag;
} lock_t;

void
init (lock_t *lock)
{
  lock->flag = 0;
}

void
lock (lock_t *lock)
{
  while (TestAndSet (&lock->flag, 1) == 1)
    ;
}

void
unlock (lock_t *lock)
{
  lock->flag = 0;
}
```

返回old_ptr的旧值，并赋予其新值

### 比较并交换（compare-and-swap）CAS

```c
int
CompareAndSwap (int *ptr, int expected, int new)
{
  int actual = *ptr;
  if (actual == expected)
    *ptr = new;
  return actual;
}
```

比较指针的值与目标值是否相同，相同则将指针的值修改为新值

### 链接的加载（load-linked）和条件式存储（store-conditional）

链接的加载指令和典型加载指令类似，都是从内存中取出值存入一个寄存器。  
关键区别在于条件式存储指令：只有上一次加载的地址在期间没有更新时，才会成功

```c
int
LoadLinked (int *ptr)
{
  return *ptr;
}

int
StoreConditional (int *ptr, int value)
{
  if (1) // loadlinked地址的值没有发生更改
    {
      *ptr = value;
      return 1;
    }
  else
    {
      return 0;
    }
}
```

```c
void
lock (lock_t *lock)
{
  while (1)
    {
      while (LoadLinked (&lock->flag) == 1)
        ;
      if (StoreConditional (&lock->flag, 1) == 1)
        {
          return;
        }
    }
}

void
unlock (lock_t *lock)
{
  lock->flag = 0;
}
```



### 获取并增加（fetch-and-add）

能原子地返回特定地址的旧值，并且让该值自增一

```c
int
FetchAndAdd (int *ptr)
{
  int old = *ptr;
  *ptr = old + 1;
  return old;
}
```

```c
typedef struct __lock_t
{
  int ticket;
  int turn;
} lock_t;

void
lock_init (lock_t *lock)
{
  lock->ticket = 0;
  lock->turn = 0;
}

void
lock (lock_t *lock)
{
  int myturn = FetchAndAdd (&lock->ticket);
  while (lock->turn != myturn)
    ; // spin
}

void
unlock (lock_t *lock)
{
  lock->turn = lock->turn + 1;

```

本方法能保证所有线程都能抢到锁。只要一个线程获得了ticket值，它最终会被调度

### 休眠代替自旋 ：使用队列

### 两阶段锁

两阶段锁的第一阶段会先自旋一段时间，希望它可以获取锁。但是如果第一阶段没有获取锁，第二阶段调用者会睡眠，直到锁可用

### 懒惰计数器

懒惰计数器通过多个局部计数器和一个全局计数器来实现一个逻辑计数器，其中每个CPU核心有一个局部计数器。每个CPU都有自己的局部计数器，不同CPU上的线程不会竞争

局部值定期转移给全局计数器（让全局计数器加上局部计数器的值）

这种局部转全局的频度，取决于一个阈值，这里称为S（表示sloppiness）  
S越小，懒惰计数器则越趋近于非扩展的计数器。S越大，扩展性越强，但是全局计数器与实际计数器的偏差越大。  
如果S大，性能很好，但是全局计数器会有延时。



